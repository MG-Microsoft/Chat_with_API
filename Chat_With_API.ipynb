{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Chains\n",
    "\n",
    "If you are just getting started, and you have relatively simple apis, you should get started with chains. Chains are a sequence of predetermined steps, so they are good to get started with as they give you more control and let you understand what is happening better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mhttps://api.open-meteo.com/v1/forecast?latitude=43.70&longitude=-79.42&current_weather=true&temperature_unit=celsius\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{\"latitude\":43.70455,\"longitude\":-79.4046,\"generationtime_ms\":0.1690387725830078,\"utc_offset_seconds\":0,\"timezone\":\"GMT\",\"timezone_abbreviation\":\"GMT\",\"elevation\":180.0,\"current_weather\":{\"temperature\":16.8,\"windspeed\":8.7,\"winddirection\":287.0,\"weathercode\":3,\"is_day\":0,\"time\":\"2023-06-06T04:00\"}}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current weather in Toronto, Canada is 16.8 degrees Celsius.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.api.prompt import API_RESPONSE_PROMPT\n",
    "from langchain.chains import APIChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from langchain.chains.api import open_meteo_docs\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"............\"\n",
    "\n",
    "llm = OpenAI(temperature=0,model_name=\"gpt-4\")\n",
    "\n",
    "chain_new = APIChain.from_llm_and_api_docs(llm, open_meteo_docs.OPEN_METEO_DOCS, verbose=True)\n",
    "\n",
    "chain_new.run('What is the weather like right now in Toronto, Canada in degrees celsius?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents\n",
    "\n",
    "\n",
    "Agents are more complex, and involve multiple queries to the LLM to understand what to do. The downside of agents are that you have less control. The upside is that they are more powerful, which allows you to use them on larger and more complex schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# URL of the file to download\n",
    "url = \"https://raw.githubusercontent.com/openai/openai-openapi/master/openapi.yaml\"\n",
    "\n",
    "# Send a HTTP request to the specified URL and save the\n",
    "# response from server in a response object called r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Make sure the request was successful\n",
    "r.raise_for_status()\n",
    "\n",
    "# Open the file in write mode and write the contents into the file\n",
    "with open(\"openapi.yaml\", 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "# Use os.rename() method to rename the file\n",
    "os.rename(\"openapi.yaml\", \"openai_openapi.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
    "with open(\"openai_openapi.yaml\") as f:\n",
    "    raw_openai_api_spec = yaml.load(f, Loader=yaml.Loader)\n",
    "openai_api_spec = reduce_openapi_spec(raw_openai_api_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: api_planner\n",
      "Action Input: I need to find the right API call to generate a short piece of advice\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. GET /engines to find the appropriate engine for generating text\n",
      "2. POST /completions with the selected engine and a prompt for generating a short piece of advice\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the plan, now I need to execute the API calls.\n",
      "Action: api_controller\n",
      "Action Input: 1. GET /engines to find the appropriate engine for generating text\n",
      "2. POST /completions with the selected engine and a prompt for generating a short piece of advice\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: {\"url\": \"https://api.openai.com/v1/engines\", \"params\": {}, \"output_instructions\": \"Extract the ids of the engines\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mwhisper-1, babbage, davinci, text-davinci-edit-001, babbage-code-search-code, text-similarity-babbage-001, code-davinci-edit-001, text-davinci-001, ada, babbage-code-search-text, babbage-similarity, code-search-babbage-text-001, text-curie-001, code-search-babbage-code-001, text-ada-001, text-similarity-ada-001, curie-instruct-beta, ada-code-search-code, ada-similarity, text-embedding-ada-002, code-search-ada-text-001, text-search-ada-query-001, davinci-search-document, ada-code-search-text, text-search-ada-doc-001, davinci-instruct-beta, text-similarity-curie-001, code-search-ada-code-001, ada-search-query\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will use the \"davinci\" engine for generating a short piece of advice.\n",
      "\n",
      "Action: requests_post\n",
      "Action Input: {\"url\": \"https://api.openai.com/v1/completions\", \"data\": {\"engine\": \"davinci\", \"prompt\": \"Give me a short piece of advice on time management.\"}, \"output_instructions\": \"Extract the text from the first choice\"}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3myou must provide a model parameter - invalid_request_error\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI cannot finish executing the plan without knowing some other information.\n",
      "\n",
      "Final Answer: I need to know the correct parameter name for specifying the engine in the POST /completions request.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mI need to know the correct parameter name for specifying the engine in the POST /completions request.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should check the OpenAPI spec to find the correct parameter name for specifying the engine in the POST /completions request.\n",
      "Action: api_planner\n",
      "Action Input: Find the correct parameter name for specifying the engine in the POST /completions request from the OpenAPI spec\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. GET /engines to retrieve the list of available engines\n",
      "2. POST /completions with the desired engine as a parameter to check the correct parameter name for specifying the engine in the request\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the updated plan, now I need to execute the API calls.\n",
      "Action: api_controller\n",
      "Action Input: 1. GET /engines to find the appropriate engine for generating text\n",
      "2. POST /completions with the selected engine and a prompt for generating a short piece of advice\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: {\"url\": \"https://api.openai.com/v1/engines\", \"params\": {}, \"output_instructions\": \"extract the ids of the engines\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mwhisper-1, babbage, davinci, text-davinci-edit-001, babbage-code-search-code, text-similarity-babbage-001, code-davinci-edit-001, text-davinci-001, ada, babbage-code-search-text, babbage-similarity, code-search-babbage-text-001, text-curie-001, code-search-babbage-code-001, text-ada-001, text-similarity-ada-001, curie-instruct-beta, ada-code-search-code, ada-similarity, text-embedding-ada-002, code-search-ada-text-001, text-search-ada-query-001, davinci-search-document, ada-code-search-text, text-search-ada-doc-001, davinci-instruct-beta, text-similarity-curie-001, code-search-ada-code-001, ada-search-query\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will use the \"davinci\" engine for generating a short piece of advice.\n",
      "\n",
      "Action: requests_post\n",
      "Action Input: {\"url\": \"https://api.openai.com/v1/completions\", \"data\": {\"engine\": \"davinci\", \"prompt\": \"Give me a short piece of advice.\"}, \"output_instructions\": \"extract the text from the first choice\"}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mYou must provide a model parameter. Error type: invalid_request_error.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI cannot finish executing the plan without knowing the correct parameter for the model.\n",
      "\n",
      "Final Answer: I need to know the correct parameter for the model to execute the POST /completions request.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mI need to know the correct parameter for the model to execute the POST /completions request.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should check the OpenAPI spec to find the correct parameter for the model in the POST /completions request.\n",
      "Action: api_planner\n",
      "Action Input: Find the correct parameter for the model in the POST /completions request from the OpenAPI spec\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. GET /models to retrieve the list of available models\n",
      "2. Choose the desired model from the list\n",
      "3. Use the chosen model as the parameter for the POST /completions request\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the updated plan, now I need to execute the API calls.\n",
      "Action: api_controller\n",
      "Action Input: 1. GET /models to retrieve the list of available models\n",
      "2. Choose the desired model from the list\n",
      "3. POST /completions with the chosen model and a prompt for generating a short piece of advice\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: requests_get\n",
      "Action Input: {\"url\": \"https://api.openai.com/v1/models\", \"params\": {}, \"output_instructions\": \"Extract the ids and names of the models\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[\n",
      "  {\n",
      "    \"id\": \"whisper-1\",\n",
      "    \"name\": \"whisper-1\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"babbage\",\n",
      "    \"name\": \"babbage\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"davinci\",\n",
      "    \"name\": \"davinci\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"text-davinci-edit-001\",\n",
      "    \"name\": \"text-davinci-edit-001\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"babbage-code-search-code\",\n",
      "    \"name\": \"babbage-code-search-code\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"text-similarity-babbage-001\",\n",
      "    \"name\": \"text-similarity-babbage-001\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"code-davinci-edit-001\",\n",
      "    \"name\": \"code-davinci-edit-001\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"text-davinci-001\",\n",
      "    \"name\": \"text-davinci-001\"\n",
      "  }\n",
      "]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will choose the \"text-davinci-001\" model for generating a short piece of advice.\n",
      "Action: requests_post\n",
      "Action Input: {\"url\": \"https://api.openai.com/v1/completions\", \"data\": {\"model\": \"text-davinci-001\", \"prompt\": \"Give me a short piece of advice on how to be more productive.\", \"max_tokens\": 50}, \"output_instructions\": \"Extract the text from the first choice\"}\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 97af1194f11e3e41e18429c7f2397787 in your message.).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe best way to be productive is to develop a good routine and stick to it. Get organized and find a system that works for you. Be disciplined and don't procrastinate. Use a timer to help you stay on track and take\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI am finished executing the plan.\n",
      "Final Answer: The best way to be productive is to develop a good routine and stick to it. Get organized and find a system that works for you. Be disciplined and don't procrastinate. Use a timer to help you stay on track and take\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe best way to be productive is to develop a good routine and stick to it. Get organized and find a system that works for you. Be disciplined and don't procrastinate. Use a timer to help you stay on track and take\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have executed the plan and generated a short piece of advice.\n",
      "Final Answer: The best way to be productive is to develop a good routine and stick to it. Get organized and find a system that works for you. Be disciplined and don't procrastinate. Use a timer to help you stay on track and take breaks as needed.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The best way to be productive is to develop a good routine and stick to it. Get organized and find a system that works for you. Be disciplined and don't procrastinate. Use a timer to help you stay on track and take breaks as needed.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents.agent_toolkits.openapi import planner\n",
    "from langchain.requests import RequestsWrapper\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\"\n",
    "}\n",
    "openai_requests_wrapper=RequestsWrapper(headers=headers)\n",
    "\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-4\", temperature=0.25)\n",
    "openai_agent = planner.create_openapi_agent(openai_api_spec, openai_requests_wrapper, llm)\n",
    "user_query = \"generate a short piece of advice\"\n",
    "openai_agent.run(user_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
